{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arabic Egyptian Text Classifier \n",
    "Based on Dataset of Tweets from twitter classified into positive and negative texts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('C:/Users/Abdullah/Desktop/archive'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22760\n",
      "22513\n"
     ]
    }
   ],
   "source": [
    "### load data \n",
    "neg_train=pd.read_csv('train_Arabic_tweets_negative_20190413.tsv',sep='\\t')\n",
    "neg_train.columns=['sentiment','text']\n",
    "len(neg_train)\n",
    "pos_train=pd.read_csv('train_Arabic_tweets_positive_20190413.tsv',sep='\\t')\n",
    "pos_train.columns=['sentiment','text']\n",
    "print(len(pos_train))\n",
    "print(len(neg_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos</td>\n",
       "      <td>ÙˆÙÙŠ Ø§Ù„Ù†Ù‡Ø§ÙŠØ© Ù„Ù† ÙŠØ¨Ù‚Ù‰Ù° Ù…Ø¹Ùƒ Ø¢Ø­Ø¯Ø¥Ù„Ø§ Ù…Ù† Ø±Ø£Ù‰Ù° Ø§Ù„Ø¬Ù…Ø§Ù„...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>Ù…Ù† Ø§Ù„Ø®ÙŠØ± Ù†ÙØ³Ù‡ ğŸ’›</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>#Ø²Ù„Ø²Ù„_Ø§Ù„Ù…Ù„Ø¹Ø¨_Ù†ØµØ±Ù†Ø§_Ø¨ÙŠÙ„Ø¹Ø¨ ÙƒÙ† Ø¹Ø§Ù„ÙŠ Ø§Ù„Ù‡Ù…Ù‡ ÙˆÙ„Ø§ ØªØ±Ø¶...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>Ø§Ù„Ø´ÙŠØ¡ Ø§Ù„ÙˆØ­ÙŠØ¯ Ø§Ù„Ø°ÙŠ ÙˆØµÙ„ÙˆØ§ ÙÙŠÙ‡ Ù„Ù„Ø¹Ø§Ù„Ù…ÙŠØ© Ù‡Ùˆ : Ø§Ù„Ù…Ø³...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>#Ø§Ù„Ø§ØªØ­Ø§Ø¯_Ø§Ù„Ù†ØµØ± Ù„Ø§ØªØ­Ø³Ø¨ÙˆÙ†Ø§ Ù†Ø³ÙŠÙ†Ø§ ÙŠØ§Ù„Ø·ÙˆØ§Ù‚ÙŠ ÙˆÙ„Ø§Ù†Ø¨ÙŠ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text\n",
       "0       pos  ÙˆÙÙŠ Ø§Ù„Ù†Ù‡Ø§ÙŠØ© Ù„Ù† ÙŠØ¨Ù‚Ù‰Ù° Ù…Ø¹Ùƒ Ø¢Ø­Ø¯Ø¥Ù„Ø§ Ù…Ù† Ø±Ø£Ù‰Ù° Ø§Ù„Ø¬Ù…Ø§Ù„...\n",
       "1       pos                                    Ù…Ù† Ø§Ù„Ø®ÙŠØ± Ù†ÙØ³Ù‡ ğŸ’›\n",
       "2       pos  #Ø²Ù„Ø²Ù„_Ø§Ù„Ù…Ù„Ø¹Ø¨_Ù†ØµØ±Ù†Ø§_Ø¨ÙŠÙ„Ø¹Ø¨ ÙƒÙ† Ø¹Ø§Ù„ÙŠ Ø§Ù„Ù‡Ù…Ù‡ ÙˆÙ„Ø§ ØªØ±Ø¶...\n",
       "3       pos  Ø§Ù„Ø´ÙŠØ¡ Ø§Ù„ÙˆØ­ÙŠØ¯ Ø§Ù„Ø°ÙŠ ÙˆØµÙ„ÙˆØ§ ÙÙŠÙ‡ Ù„Ù„Ø¹Ø§Ù„Ù…ÙŠØ© Ù‡Ùˆ : Ø§Ù„Ù…Ø³...\n",
       "4       pos  #Ø§Ù„Ø§ØªØ­Ø§Ø¯_Ø§Ù„Ù†ØµØ± Ù„Ø§ØªØ­Ø³Ø¨ÙˆÙ†Ø§ Ù†Ø³ÙŠÙ†Ø§ ÙŠØ§Ù„Ø·ÙˆØ§Ù‚ÙŠ ÙˆÙ„Ø§Ù†Ø¨ÙŠ..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>ØªÙˆÙ‚Ø¹Øª Ø§Ø°Ø§ Ø¬Ø§Øª Ø¯Ø§Ø±ÙŠØ§ Ø¨Ø´ÙˆÙÙ‡Ù… ÙƒØ§Ù…Ù„ÙŠÙ† Ø¨Ø³ Ù„ÙŠ Ù„Ù„Ø­ÙŠÙ† ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>#Ø§Ù„Ø§Ù‡Ù„ÙŠ_Ø§Ù„Ù‡Ù„Ø§Ù„ Ø§ÙƒØªØ¨ ØªÙˆÙ‚Ø¹Ùƒ Ù„Ù†ØªÙŠØ¬Ø© Ù„Ù‚Ø§Ø¡ Ø§Ù„Ù‡Ù„Ø§Ù„ Ùˆ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>Ù†Ø¹Ù…Ø© Ø§Ù„Ù…Ø¶Ø§Ø¯Ø§Øª Ø§Ù„Ø­ÙŠÙˆÙŠØ© . ØªØ¶Ø¹ Ù‚Ø·Ø±Ø©ğŸ’§Ù…Ø¶Ø§Ø¯ Ø¨Ù†Ø³Ù„ÙŠÙ† Ø¹...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>Ø§Ù„Ø¯ÙˆØ¯Ùˆ Ø¬Ø§ÙŠÙ‡ ØªÙƒÙ…Ù„ Ø¹Ù„ÙŠ ğŸ’”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>Ø£Ø­Ø¨Ø¨ØªÙ‡ Ø­ØªÙ‰ Ø£Ù‚Ù†Ø¹Ù†Ù‰ Ø¥Ù† Ù…Ø§ ÙØ§Øª Ù…Ù† Ø§Ù„Ø¹Ù…Ø± ÙƒØ§Ù† Ø¥Ù†ØªØ¸Ø§...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text\n",
       "0       neg  ØªÙˆÙ‚Ø¹Øª Ø§Ø°Ø§ Ø¬Ø§Øª Ø¯Ø§Ø±ÙŠØ§ Ø¨Ø´ÙˆÙÙ‡Ù… ÙƒØ§Ù…Ù„ÙŠÙ† Ø¨Ø³ Ù„ÙŠ Ù„Ù„Ø­ÙŠÙ† ...\n",
       "1       neg  #Ø§Ù„Ø§Ù‡Ù„ÙŠ_Ø§Ù„Ù‡Ù„Ø§Ù„ Ø§ÙƒØªØ¨ ØªÙˆÙ‚Ø¹Ùƒ Ù„Ù†ØªÙŠØ¬Ø© Ù„Ù‚Ø§Ø¡ Ø§Ù„Ù‡Ù„Ø§Ù„ Ùˆ...\n",
       "2       neg  Ù†Ø¹Ù…Ø© Ø§Ù„Ù…Ø¶Ø§Ø¯Ø§Øª Ø§Ù„Ø­ÙŠÙˆÙŠØ© . ØªØ¶Ø¹ Ù‚Ø·Ø±Ø©ğŸ’§Ù…Ø¶Ø§Ø¯ Ø¨Ù†Ø³Ù„ÙŠÙ† Ø¹...\n",
       "3       neg                             Ø§Ù„Ø¯ÙˆØ¯Ùˆ Ø¬Ø§ÙŠÙ‡ ØªÙƒÙ…Ù„ Ø¹Ù„ÙŠ ğŸ’”\n",
       "4       neg  Ø£Ø­Ø¨Ø¨ØªÙ‡ Ø­ØªÙ‰ Ø£Ù‚Ù†Ø¹Ù†Ù‰ Ø¥Ù† Ù…Ø§ ÙØ§Øª Ù…Ù† Ø§Ù„Ø¹Ù…Ø± ÙƒØ§Ù† Ø¥Ù†ØªØ¸Ø§..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45273"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## concatenate data \n",
    "data=pd.concat([neg_train,pos_train])\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8305</th>\n",
       "      <td>neg</td>\n",
       "      <td>Ø§ÙŠ Ù…Ø¹Ø¬Ø¨ Ø³Ø±ÙŠ Ø¨Ø¹Ø¯ ğŸ¤”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22198</th>\n",
       "      <td>pos</td>\n",
       "      <td>Ø§Ø¹Ù„Ù‚ Ø§Ø­Ù„Ø§Ù…ÙŠ Ø¹Ù„Ù‰ Ø­Ø§ÙØ© #Ø§Ù„ØºÙŠÙ… Ø§Ù† Ø·Ø­Ù†Ø§ #ØºÙŠØ« ÙˆØ§Ù† Ø¨...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6516</th>\n",
       "      <td>pos</td>\n",
       "      <td>Ø®Ø±Ø¨Øª Ø¹Ù„ÙŠÙƒ ğŸ˜œ ğŸ‘‡ğŸ˜‚ğŸ˜‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10638</th>\n",
       "      <td>pos</td>\n",
       "      <td>ÙŠØ³Ø¹Ø¯ ØµØ¨Ø§Ø§Ø­Ùƒ ğŸŒ¹</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6470</th>\n",
       "      <td>pos</td>\n",
       "      <td>Ø§Ù„ÙŠ ÙƒØ§ØªØ¨Ùˆ Ø±Ø¨ Ø§Ù„Ø¹Ø¨Ø§Ø¯ Ø±Ø§Ø­ ØªØ´ÙˆÙÙˆ Ø§Ù„Ø¹ÙŠÙ† ÙˆØ§Ù„Ø£Ø¬Ø¯Ø± ÙŠÙ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                               text\n",
       "8305        neg                                  Ø§ÙŠ Ù…Ø¹Ø¬Ø¨ Ø³Ø±ÙŠ Ø¨Ø¹Ø¯ ğŸ¤”\n",
       "22198       pos  Ø§Ø¹Ù„Ù‚ Ø§Ø­Ù„Ø§Ù…ÙŠ Ø¹Ù„Ù‰ Ø­Ø§ÙØ© #Ø§Ù„ØºÙŠÙ… Ø§Ù† Ø·Ø­Ù†Ø§ #ØºÙŠØ« ÙˆØ§Ù† Ø¨...\n",
       "6516        pos                                    Ø®Ø±Ø¨Øª Ø¹Ù„ÙŠÙƒ ğŸ˜œ ğŸ‘‡ğŸ˜‚ğŸ˜‚\n",
       "10638       pos                                      ÙŠØ³Ø¹Ø¯ ØµØ¨Ø§Ø§Ø­Ùƒ ğŸŒ¹\n",
       "6470        pos  Ø§Ù„ÙŠ ÙƒØ§ØªØ¨Ùˆ Ø±Ø¨ Ø§Ù„Ø¹Ø¨Ø§Ø¯ Ø±Ø§Ø­ ØªØ´ÙˆÙÙˆ Ø§Ù„Ø¹ÙŠÙ† ÙˆØ§Ù„Ø£Ø¬Ø¯Ø± ÙŠÙ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## shufle data\n",
    "from sklearn.utils import shuffle\n",
    "shuffled_data = shuffle(data)\n",
    "shuffled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## convert pos to 1 and neg to 0\n",
    "shuffled_data['sentiment']=shuffled_data['sentiment'].apply(lambda x: 1 if x =='pos' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8305</th>\n",
       "      <td>0</td>\n",
       "      <td>Ø§ÙŠ Ù…Ø¹Ø¬Ø¨ Ø³Ø±ÙŠ Ø¨Ø¹Ø¯ ğŸ¤”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22198</th>\n",
       "      <td>1</td>\n",
       "      <td>Ø§Ø¹Ù„Ù‚ Ø§Ø­Ù„Ø§Ù…ÙŠ Ø¹Ù„Ù‰ Ø­Ø§ÙØ© #Ø§Ù„ØºÙŠÙ… Ø§Ù† Ø·Ø­Ù†Ø§ #ØºÙŠØ« ÙˆØ§Ù† Ø¨...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6516</th>\n",
       "      <td>1</td>\n",
       "      <td>Ø®Ø±Ø¨Øª Ø¹Ù„ÙŠÙƒ ğŸ˜œ ğŸ‘‡ğŸ˜‚ğŸ˜‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10638</th>\n",
       "      <td>1</td>\n",
       "      <td>ÙŠØ³Ø¹Ø¯ ØµØ¨Ø§Ø§Ø­Ùƒ ğŸŒ¹</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6470</th>\n",
       "      <td>1</td>\n",
       "      <td>Ø§Ù„ÙŠ ÙƒØ§ØªØ¨Ùˆ Ø±Ø¨ Ø§Ù„Ø¹Ø¨Ø§Ø¯ Ø±Ø§Ø­ ØªØ´ÙˆÙÙˆ Ø§Ù„Ø¹ÙŠÙ† ÙˆØ§Ù„Ø£Ø¬Ø¯Ø± ÙŠÙ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                               text\n",
       "8305           0                                  Ø§ÙŠ Ù…Ø¹Ø¬Ø¨ Ø³Ø±ÙŠ Ø¨Ø¹Ø¯ ğŸ¤”\n",
       "22198          1  Ø§Ø¹Ù„Ù‚ Ø§Ø­Ù„Ø§Ù…ÙŠ Ø¹Ù„Ù‰ Ø­Ø§ÙØ© #Ø§Ù„ØºÙŠÙ… Ø§Ù† Ø·Ø­Ù†Ø§ #ØºÙŠØ« ÙˆØ§Ù† Ø¨...\n",
       "6516           1                                    Ø®Ø±Ø¨Øª Ø¹Ù„ÙŠÙƒ ğŸ˜œ ğŸ‘‡ğŸ˜‚ğŸ˜‚\n",
       "10638          1                                      ÙŠØ³Ø¹Ø¯ ØµØ¨Ø§Ø§Ø­Ùƒ ğŸŒ¹\n",
       "6470           1  Ø§Ù„ÙŠ ÙƒØ§ØªØ¨Ùˆ Ø±Ø¨ Ø§Ù„Ø¹Ø¨Ø§Ø¯ Ø±Ø§Ø­ ØªØ´ÙˆÙÙˆ Ø§Ù„Ø¹ÙŠÙ† ÙˆØ§Ù„Ø£Ø¬Ø¯Ø± ÙŠÙ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\abdullah\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\abdullah\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\abdullah\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\abdullah\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\abdullah\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\abdullah\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from keras.models import Model ,Sequential\n",
    "from keras.layers import Embedding ,Dense ,Dropout , LSTM ,Input ,Activation , Bidirectional ,GlobalMaxPool1D\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.initializers import glorot_uniform\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "def load_w2v(file_path,binary):\n",
    "    return KeyedVectors.load_word2vec_format(file_path,binary=binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w2v = load_w2v(\"wiki.arz.vec\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54595\n"
     ]
    }
   ],
   "source": [
    "print(len(w2v.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n",
      "[('Ù…Ø­Ø³Ù†', 0.7458980083465576), ('Ø­Ø³Ù†ØŒ', 0.7444434762001038), ('Ø¨Ø­Ø³Ù†', 0.743319034576416), ('ÙˆØ­Ø³Ù†', 0.7386170029640198), ('Ù„Ø­Ø³Ù†', 0.7364068031311035), ('Ø­Ø³Ù†Ùƒ', 0.7337351441383362), ('Ø­Ø³Ù†Ù‡', 0.7143272161483765), ('Ø­Ø³Ù†Ø§Ø¡', 0.7094866633415222), ('ÙŠØ­Ø³Ù†', 0.6863618493080139), ('Ø­Ø³Ù†ÙŠ', 0.6850252747535706)]\n"
     ]
    }
   ],
   "source": [
    "sample=w2v['Ø­Ø³Ù†']\n",
    "print(sample.shape)\n",
    "print(w2v.most_similar('Ø­Ø³Ù†'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ØŒ', 'Ø¡', 'Ø¡Ù', 'Ø¢', 'Ø¢Ø¨', 'Ø¢Ø°Ø§Ø±', 'Ø¢Ø¶', 'Ø¢Ù„', 'Ø¢Ù…ÙŠÙ†Ù', 'Ø¢Ù†Ø§Ø¡', 'Ø¢Ù†ÙØ§', 'Ø¢Ù‡', 'Ø¢Ù‡Ø§Ù‹', 'Ø¢Ù‡Ù', 'Ø¢Ù‡Ù', 'Ø£', 'Ø£Ø¨Ø¯Ø§', 'Ø£Ø¨Ø±ÙŠÙ„', 'Ø£Ø¨Ùˆ', 'Ø£Ø¨ÙŒ', 'Ø£Ø¬Ù„', 'Ø£Ø¬Ù…Ø¹', 'Ø£Ø­Ø¯', 'Ø£Ø®Ø¨Ø±', 'Ø£Ø®Ø°', 'Ø£Ø®Ùˆ', 'Ø£Ø®ÙŒ', 'Ø£Ø±Ø¨Ø¹', 'Ø£Ø±Ø¨Ø¹Ø§Ø¡', 'Ø£Ø±Ø¨Ø¹Ø©', 'Ø£Ø±Ø¨Ø¹Ù…Ø¦Ø©', 'Ø£Ø±Ø¨Ø¹Ù…Ø§Ø¦Ø©', 'Ø£Ø±Ù‰', 'Ø£Ø³ÙƒÙ†', 'Ø£ØµØ¨Ø­', 'Ø£ØµÙ„Ø§', 'Ø£Ø¶Ø­Ù‰', 'Ø£Ø·Ø¹Ù…', 'Ø£Ø¹Ø·Ù‰', 'Ø£Ø¹Ù„Ù…', 'Ø£ØºØ³Ø·Ø³', 'Ø£ÙØ±ÙŠÙ„', 'Ø£ÙØ¹Ù„ Ø¨Ù‡', 'Ø£ÙÙÙ‘', 'Ø£Ù‚Ø¨Ù„', 'Ø£ÙƒØªÙˆØ¨Ø±', 'Ø£Ù„', 'Ø£Ù„Ø§', 'Ø£Ù„Ù', 'Ø£Ù„ÙÙ‰', 'Ø£Ù…', 'Ø£Ù…Ø§', 'Ø£Ù…Ø§Ù…', 'Ø£Ù…Ø§Ù…Ùƒ', 'Ø£Ù…Ø§Ù…ÙƒÙ', 'Ø£Ù…Ø¯', 'Ø£Ù…Ø³', 'Ø£Ù…Ø³Ù‰', 'Ø£Ù…Ù‘Ø§', 'Ø£Ù†', 'Ø£Ù†Ø§', 'Ø£Ù†Ø¨Ø£', 'Ø£Ù†Øª', 'Ø£Ù†ØªÙ…', 'Ø£Ù†ØªÙ…Ø§', 'Ø£Ù†ØªÙ†', 'Ø£Ù†ØªÙ', 'Ø£Ù†Ø´Ø£', 'Ø£Ù†Ù‡', 'Ø£Ù†Ù‹Ù‘', 'Ø£Ù†Ù‘Ù‰', 'Ø£Ù‡Ù„Ø§', 'Ø£Ùˆ', 'Ø£ÙˆØª', 'Ø£ÙˆØ´Ùƒ', 'Ø£ÙˆÙ„', 'Ø£ÙˆÙ„Ø¦Ùƒ', 'Ø£ÙˆÙ„Ø§Ø¡', 'Ø£ÙˆÙ„Ø§Ù„Ùƒ', 'Ø£ÙˆÙ‘Ù‡Ù’', 'Ø£Ù‰', 'Ø£ÙŠ', 'Ø£ÙŠØ§', 'Ø£ÙŠØ§Ø±', 'Ø£ÙŠØ¶Ø§', 'Ø£ÙŠÙ„ÙˆÙ„', 'Ø£ÙŠÙ†', 'Ø£ÙŠÙ‘', 'Ø£ÙŠÙ‘Ø§Ù†', 'Ø£ÙÙÙÙ‘', 'Ø¤', 'Ø¥Ø­Ø¯Ù‰', 'Ø¥Ø°', 'Ø¥Ø°Ø§', 'Ø¥Ø°Ø§Ù‹', 'Ø¥Ø°Ù…Ø§', 'Ø¥Ø°Ù†', 'Ø¥Ø²Ø§Ø¡', 'Ø¥Ù„Ù‰', 'Ø¥Ù„ÙŠ', 'Ø¥Ù„ÙŠÙƒÙ…', 'Ø¥Ù„ÙŠÙƒÙ…Ø§', 'Ø¥Ù„ÙŠÙƒÙ†Ù‘', 'Ø¥Ù„ÙŠÙƒÙ', 'Ø¥Ù„ÙÙŠÙ’ÙƒÙ', 'Ø¥Ù„Ù‘Ø§', 'Ø¥Ù…Ù‘Ø§', 'Ø¥Ù†', 'Ø¥Ù†ÙÙ‘', 'Ø¥Ù‰', 'Ø¥ÙŠØ§Ùƒ', 'Ø¥ÙŠØ§ÙƒÙ…', 'Ø¥ÙŠØ§ÙƒÙ…Ø§', 'Ø¥ÙŠØ§ÙƒÙ†', 'Ø¥ÙŠØ§Ù†Ø§', 'Ø¥ÙŠØ§Ù‡', 'Ø¥ÙŠØ§Ù‡Ø§', 'Ø¥ÙŠØ§Ù‡Ù…', 'Ø¥ÙŠØ§Ù‡Ù…Ø§', 'Ø¥ÙŠØ§Ù‡Ù†', 'Ø¥ÙŠØ§ÙŠ', 'Ø¥ÙŠÙ‡Ù', 'Ø¦', 'Ø§', 'Ø§?', 'Ø§?Ù‰', 'Ø§Ø§Ù„Ø§', 'Ø§Ø§Ù„ØªÙ‰', 'Ø§Ø¨ØªØ¯Ø£', 'Ø§Ø¨ÙŠÙ†', 'Ø§ØªØ®Ø°', 'Ø§Ø«Ø±', 'Ø§Ø«Ù†Ø§', 'Ø§Ø«Ù†Ø§Ù†', 'Ø§Ø«Ù†ÙŠ', 'Ø§Ø«Ù†ÙŠÙ†', 'Ø§Ø¬Ù„', 'Ø§Ø­Ø¯', 'Ø§Ø®Ø±Ù‰', 'Ø§Ø®Ù„ÙˆÙ„Ù‚', 'Ø§Ø°Ø§', 'Ø§Ø±Ø¨Ø¹Ø©', 'Ø§Ø±Ø¨Ø¹ÙˆÙ†', 'Ø§Ø±Ø¨Ø¹ÙŠÙ†', 'Ø§Ø±ØªØ¯Ù‘', 'Ø§Ø³ØªØ­Ø§Ù„', 'Ø§ØµØ¨Ø­', 'Ø§Ø¶Ø­Ù‰', 'Ø§Ø·Ø§Ø±', 'Ø§Ø¹Ø§Ø¯Ø©', 'Ø§Ø¹Ù„Ù†Øª', 'Ø§Ù', 'Ø§ÙƒØ«Ø±', 'Ø§ÙƒØ¯', 'Ø§Ù„Ø¢Ù†', 'Ø§Ù„Ø£Ù„Ø§Ø¡', 'Ø§Ù„Ø£Ù„Ù‰', 'Ø§Ù„Ø§', 'Ø§Ù„Ø§Ø®ÙŠØ±Ø©', 'Ø§Ù„Ø§Ù†', 'Ø§Ù„Ø§ÙˆÙ„', 'Ø§Ù„Ø§ÙˆÙ„Ù‰', 'Ø§Ù„ØªÙ‰', 'Ø§Ù„ØªÙŠ', 'Ø§Ù„Ø«Ø§Ù†ÙŠ', 'Ø§Ù„Ø«Ø§Ù†ÙŠØ©', 'Ø§Ù„Ø­Ø§Ù„ÙŠ', 'Ø§Ù„Ø°Ø§ØªÙŠ', 'Ø§Ù„Ø°Ù‰', 'Ø§Ù„Ø°ÙŠ', 'Ø§Ù„Ø°ÙŠÙ†', 'Ø§Ù„Ø³Ø§Ø¨Ù‚', 'Ø§Ù„Ù', 'Ø§Ù„Ù„Ø§ØªÙŠ', 'Ø§Ù„Ù„ØªØ§Ù†', 'Ø§Ù„Ù„ØªÙŠØ§', 'Ø§Ù„Ù„ØªÙŠÙ†', 'Ø§Ù„Ù„Ø°Ø§Ù†', 'Ø§Ù„Ù„Ø°ÙŠÙ†', 'Ø§Ù„Ù„ÙˆØ§ØªÙŠ', 'Ø§Ù„Ù…Ø§Ø¶ÙŠ', 'Ø§Ù„Ù…Ù‚Ø¨Ù„', 'Ø§Ù„ÙˆÙ‚Øª', 'Ø§Ù„Ù‰', 'Ø§Ù„ÙŠ', 'Ø§Ù„ÙŠÙ‡', 'Ø§Ù„ÙŠÙ‡Ø§', 'Ø§Ù„ÙŠÙˆÙ…', 'Ø§Ù…Ø§', 'Ø§Ù…Ø§Ù…', 'Ø§Ù…Ø³', 'Ø§Ù…Ø³Ù‰', 'Ø§Ù†', 'Ø§Ù†Ø¨Ø±Ù‰', 'Ø§Ù†Ù‚Ù„Ø¨', 'Ø§Ù†Ù‡', 'Ø§Ù†Ù‡Ø§', 'Ø§Ùˆ', 'Ø§ÙˆÙ„', 'Ø§ÙŠ', 'Ø§ÙŠØ§Ø±', 'Ø§ÙŠØ§Ù…', 'Ø§ÙŠØ¶Ø§', 'Ø¨', 'Ø¨Ø¤Ø³Ø§', 'Ø¨Ø¥Ù†', 'Ø¨Ø¦Ø³', 'Ø¨Ø§Ø¡', 'Ø¨Ø§Øª', 'Ø¨Ø§Ø³Ù…', 'Ø¨Ø§Ù†', 'Ø¨Ø®Ù', 'Ø¨Ø¯', 'Ø¨Ø¯Ù„Ø§', 'Ø¨Ø±Ø³', 'Ø¨Ø³Ø¨Ø¨', 'Ø¨Ø³Ù‘', 'Ø¨Ø´ÙƒÙ„', 'Ø¨Ø¶Ø¹', 'Ø¨Ø·Ø¢Ù†', 'Ø¨Ø¹Ø¯', 'Ø¨Ø¹Ø¯Ø§', 'Ø¨Ø¹Ø¶', 'Ø¨ØºØªØ©', 'Ø¨Ù„', 'Ø¨Ù„Ù‰', 'Ø¨Ù†', 'Ø¨Ù‡', 'Ø¨Ù‡Ø§', 'Ø¨Ù‡Ø°Ø§', 'Ø¨ÙŠØ¯', 'Ø¨ÙŠÙ†', 'Ø¨ÙØ³Ù’', 'Ø¨ÙÙ„Ù’Ù‡Ù', 'Ø©', 'Øª', 'ØªØ§Ø¡', 'ØªØ§Ø±Ø©', 'ØªØ§Ø³Ø¹', 'ØªØ§Ù†Ù', 'ØªØ§Ù†ÙÙƒ', 'ØªØ¨Ø¯Ù‘Ù„', 'ØªØ¬Ø§Ù‡', 'ØªØ­Øª', 'ØªØ­ÙˆÙ‘Ù„', 'ØªØ®Ø°', 'ØªØ±Ùƒ', 'ØªØ³Ø¹', 'ØªØ³Ø¹Ø©', 'ØªØ³Ø¹Ù…Ø¦Ø©', 'ØªØ³Ø¹Ù…Ø§Ø¦Ø©', 'ØªØ³Ø¹ÙˆÙ†', 'ØªØ³Ø¹ÙŠÙ†', 'ØªØ´Ø±ÙŠÙ†', 'ØªØ¹Ø³Ø§', 'ØªØ¹Ù„ÙÙ‘Ù…', 'ØªÙØ¹Ù„Ø§Ù†', 'ØªÙØ¹Ù„ÙˆÙ†', 'ØªÙØ¹Ù„ÙŠÙ†', 'ØªÙƒÙˆÙ†', 'ØªÙ„Ù‚Ø§Ø¡', 'ØªÙ„Ùƒ', 'ØªÙ…', 'ØªÙ…ÙˆØ²', 'ØªÙŠÙ†Ùƒ', 'ØªÙÙŠÙ’Ù†Ù', 'ØªÙÙ‡', 'ØªÙÙŠ', 'Ø«', 'Ø«Ø§Ø¡', 'Ø«Ø§Ù„Ø«', 'Ø«Ø§Ù…Ù†', 'Ø«Ø§Ù†', 'Ø«Ø§Ù†ÙŠ', 'Ø«Ù„Ø§Ø«', 'Ø«Ù„Ø§Ø«Ø§Ø¡', 'Ø«Ù„Ø§Ø«Ø©', 'Ø«Ù„Ø§Ø«Ù…Ø¦Ø©', 'Ø«Ù„Ø§Ø«Ù…Ø§Ø¦Ø©', 'Ø«Ù„Ø§Ø«ÙˆÙ†', 'Ø«Ù„Ø§Ø«ÙŠÙ†', 'Ø«Ù…', 'Ø«Ù…Ø§Ù†', 'Ø«Ù…Ø§Ù†Ù…Ø¦Ø©', 'Ø«Ù…Ø§Ù†ÙˆÙ†', 'Ø«Ù…Ø§Ù†ÙŠ', 'Ø«Ù…Ø§Ù†ÙŠØ©', 'Ø«Ù…Ø§Ù†ÙŠÙ†', 'Ø«Ù…Ù†Ù…Ø¦Ø©', 'Ø«Ù…ÙÙ‘', 'Ø«Ù…Ù‘', 'Ø«Ù…Ù‘Ø©', 'Ø¬', 'Ø¬Ø§Ù†ÙÙŠ', 'Ø¬Ø¯Ø§', 'Ø¬Ø¹Ù„', 'Ø¬Ù„Ù„', 'Ø¬Ù…Ø¹Ø©', 'Ø¬Ù…ÙŠØ¹', 'Ø¬Ù†ÙŠÙ‡', 'Ø¬ÙˆØ§Ù†', 'Ø¬ÙˆÙŠÙ„ÙŠØ©', 'Ø¬ÙŠØ±', 'Ø¬ÙŠÙ…', 'Ø­', 'Ø­Ø§Ø¡', 'Ø­Ø§Ø¯ÙŠ', 'Ø­Ø§Ø±', 'Ø­Ø§Ø´Ø§', 'Ø­Ø§Ù„ÙŠØ§', 'Ø­Ø§ÙŠ', 'Ø­Ø¨Ø°Ø§', 'Ø­Ø¨ÙŠØ¨', 'Ø­ØªÙ‰', 'Ø­Ø¬Ø§', 'Ø­Ø¯ÙØ«', 'Ø­Ø±Ù‰', 'Ø­Ø²ÙŠØ±Ø§Ù†', 'Ø­Ø³Ø¨', 'Ø­Ù‚Ø§', 'Ø­Ù…Ø¯Ø§', 'Ø­Ù…Ùˆ', 'Ø­Ù…ÙŒ', 'Ø­ÙˆØ§Ù„Ù‰', 'Ø­ÙˆÙ„', 'Ø­ÙŠØ«', 'Ø­ÙŠØ«Ù…Ø§', 'Ø­ÙŠÙ†', 'Ø­ÙŠÙÙ‘', 'Ø­ÙØ°Ø§Ø±Ù', 'Ø®', 'Ø®Ø§Ø¡', 'Ø®Ø§ØµØ©', 'Ø®Ø§Ù„', 'Ø®Ø§Ù…Ø³', 'Ø®Ø¨ÙÙ‘Ø±', 'Ø®Ù„Ø§', 'Ø®Ù„Ø§ÙØ§', 'Ø®Ù„Ø§Ù„', 'Ø®Ù„Ù', 'Ø®Ù…Ø³', 'Ø®Ù…Ø³Ø©', 'Ø®Ù…Ø³Ù…Ø¦Ø©', 'Ø®Ù…Ø³Ù…Ø§Ø¦Ø©', 'Ø®Ù…Ø³ÙˆÙ†', 'Ø®Ù…Ø³ÙŠÙ†', 'Ø®Ù…ÙŠØ³', 'Ø¯', 'Ø¯Ø§Ù„', 'Ø¯Ø±Ù‡Ù…', 'Ø¯Ø±Ù‰', 'Ø¯ÙˆØ§Ù„ÙŠÙƒ', 'Ø¯ÙˆÙ„Ø§Ø±', 'Ø¯ÙˆÙ†', 'Ø¯ÙˆÙ†Ùƒ', 'Ø¯ÙŠØ³Ù…Ø¨Ø±', 'Ø¯ÙŠÙ†Ø§Ø±', 'Ø°', 'Ø°Ø§', 'Ø°Ø§Øª', 'Ø°Ø§Ùƒ', 'Ø°Ø§Ù„', 'Ø°Ø§Ù†Ùƒ', 'Ø°Ø§Ù†Ù', 'Ø°Ù„Ùƒ', 'Ø°Ù‡Ø¨', 'Ø°Ùˆ', 'Ø°ÙŠØª', 'Ø°ÙŠÙ†Ùƒ', 'Ø°ÙÙŠÙ’Ù†Ù', 'Ø°ÙÙ‡', 'Ø°ÙÙŠ', 'Ø±', 'Ø±Ø£Ù‰', 'Ø±Ø§Ø¡', 'Ø±Ø§Ø¨Ø¹', 'Ø±Ø§Ø­', 'Ø±Ø¬Ø¹', 'Ø±Ø²Ù‚', 'Ø±ÙˆÙŠØ¯Ùƒ', 'Ø±ÙŠØ§Ù„', 'Ø±ÙŠØ«', 'Ø±ÙØ¨ÙÙ‘', 'Ø²', 'Ø²Ø§ÙŠ', 'Ø²Ø¹Ù…', 'Ø²ÙˆØ¯', 'Ø²ÙŠØ§Ø±Ø©', 'Ø³', 'Ø³Ø§Ø¡', 'Ø³Ø§Ø¨Ø¹', 'Ø³Ø§Ø¯Ø³', 'Ø³Ø¨Øª', 'Ø³Ø¨ØªÙ…Ø¨Ø±', 'Ø³Ø¨Ø­Ø§Ù†', 'Ø³Ø¨Ø¹', 'Ø³Ø¨Ø¹Ø©', 'Ø³Ø¨Ø¹Ù…Ø¦Ø©', 'Ø³Ø¨Ø¹Ù…Ø§Ø¦Ø©', 'Ø³Ø¨Ø¹ÙˆÙ†', 'Ø³Ø¨Ø¹ÙŠÙ†', 'Ø³Øª', 'Ø³ØªØ©', 'Ø³ØªÙƒÙˆÙ†', 'Ø³ØªÙ…Ø¦Ø©', 'Ø³ØªÙ…Ø§Ø¦Ø©', 'Ø³ØªÙˆÙ†', 'Ø³ØªÙŠÙ†', 'Ø³Ø­Ù‚Ø§', 'Ø³Ø±Ø§', 'Ø³Ø±Ø¹Ø§Ù†', 'Ø³Ù‚Ù‰', 'Ø³Ù…Ø¹Ø§', 'Ø³Ù†Ø©', 'Ø³Ù†ØªÙŠÙ…', 'Ø³Ù†ÙˆØ§Øª', 'Ø³ÙˆÙ', 'Ø³ÙˆÙ‰', 'Ø³ÙŠÙ†', 'Ø´', 'Ø´Ø¨Ø§Ø·', 'Ø´Ø¨Ù‡', 'Ø´ØªØ§Ù†Ù', 'Ø´Ø®ØµØ§', 'Ø´Ø±Ø¹', 'Ø´Ù…Ø§Ù„', 'Ø´ÙŠÙƒÙ„', 'Ø´ÙŠÙ†', 'Ø´ÙØªÙÙ‘Ø§Ù†Ù', 'Øµ', 'ØµØ§Ø¯', 'ØµØ§Ø±', 'ØµØ¨Ø§Ø­', 'ØµØ¨Ø±', 'ØµØ¨Ø±Ø§', 'ØµØ¯Ù‚Ø§', 'ØµØ±Ø§Ø­Ø©', 'ØµÙØ±', 'ØµÙ‡Ù', 'ØµÙ‡Ù’', 'Ø¶', 'Ø¶Ø§Ø¯', 'Ø¶Ø­ÙˆØ©', 'Ø¶Ø¯', 'Ø¶Ù…Ù†', 'Ø·', 'Ø·Ø§Ø¡', 'Ø·Ø§Ù‚', 'Ø·Ø§Ù„Ù…Ø§', 'Ø·Ø±Ø§', 'Ø·ÙÙ‚', 'Ø·ÙÙ‚', 'Ø¸', 'Ø¸Ø§Ø¡', 'Ø¸Ù„', 'Ø¸Ù„Ù‘', 'Ø¸Ù†ÙÙ‘', 'Ø¹', 'Ø¹Ø§Ø¯', 'Ø¹Ø§Ø´Ø±', 'Ø¹Ø§Ù…', 'Ø¹Ø§Ù…Ø§', 'Ø¹Ø§Ù…Ø©', 'Ø¹Ø¬Ø¨Ø§', 'Ø¹Ø¯Ø§', 'Ø¹Ø¯Ø©', 'Ø¹Ø¯Ø¯', 'Ø¹Ø¯Ù…', 'Ø¹Ø¯ÙÙ‘', 'Ø¹Ø³Ù‰', 'Ø¹Ø´Ø±', 'Ø¹Ø´Ø±Ø©', 'Ø¹Ø´Ø±ÙˆÙ†', 'Ø¹Ø´Ø±ÙŠÙ†', 'Ø¹Ù„', 'Ø¹Ù„Ù‚', 'Ø¹Ù„Ù…', 'Ø¹Ù„Ù‰', 'Ø¹Ù„ÙŠ', 'Ø¹Ù„ÙŠÙƒ', 'Ø¹Ù„ÙŠÙ‡', 'Ø¹Ù„ÙŠÙ‡Ø§', 'Ø¹Ù„Ù‹Ù‘', 'Ø¹Ù†', 'Ø¹Ù†Ø¯', 'Ø¹Ù†Ø¯Ù…Ø§', 'Ø¹Ù†Ù‡', 'Ø¹Ù†Ù‡Ø§', 'Ø¹ÙˆØ¶', 'Ø¹ÙŠØ§Ù†Ø§', 'Ø¹ÙŠÙ†', 'Ø¹ÙØ¯ÙØ³Ù’', 'Øº', 'ØºØ§Ø¯Ø±', 'ØºØ§Ù„Ø¨Ø§', 'ØºØ¯Ø§', 'ØºØ¯Ø§Ø©', 'ØºÙŠØ±', 'ØºÙŠÙ†', 'Ù€', 'Ù', 'ÙØ¥Ù†', 'ÙØ§Ø¡', 'ÙØ§Ù†', 'ÙØ§Ù†Ù‡', 'ÙØ¨Ø±Ø§ÙŠØ±', 'ÙØ±Ø§Ø¯Ù‰', 'ÙØ¶Ù„Ø§', 'ÙÙ‚Ø¯', 'ÙÙ‚Ø·', 'ÙÙƒØ§Ù†', 'ÙÙ„Ø§Ù†', 'ÙÙ„Ø³', 'ÙÙ‡Ùˆ', 'ÙÙˆ', 'ÙÙˆÙ‚', 'ÙÙ‰', 'ÙÙŠ', 'ÙÙŠÙØ±ÙŠ', 'ÙÙŠÙ‡', 'ÙÙŠÙ‡Ø§', 'Ù‚', 'Ù‚Ø§Ø·Ø¨Ø©', 'Ù‚Ø§Ù', 'Ù‚Ø§Ù„', 'Ù‚Ø§Ù…', 'Ù‚Ø¨Ù„', 'Ù‚Ø¯', 'Ù‚Ø±Ø´', 'Ù‚Ø·Ù‘', 'Ù‚Ù„Ù…Ø§', 'Ù‚ÙˆØ©', 'Ùƒ', 'ÙƒØ£Ù†', 'ÙƒØ£Ù†Ù‘', 'ÙƒØ£ÙŠÙ‘', 'ÙƒØ£ÙŠÙ‘Ù†', 'ÙƒØ§Ø¯', 'ÙƒØ§Ù', 'ÙƒØ§Ù†', 'ÙƒØ§Ù†Øª', 'ÙƒØ§Ù†ÙˆÙ†', 'ÙƒØ«ÙŠØ±Ø§', 'ÙƒØ°Ø§', 'ÙƒØ°Ù„Ùƒ', 'ÙƒØ±Ø¨', 'ÙƒØ³Ø§', 'ÙƒÙ„', 'ÙƒÙ„ØªØ§', 'ÙƒÙ„Ù…', 'ÙƒÙ„ÙÙ‘Ø§', 'ÙƒÙ„Ù‘Ù…Ø§', 'ÙƒÙ…', 'ÙƒÙ…Ø§', 'ÙƒÙ†', 'ÙƒÙ‰', 'ÙƒÙŠØª', 'ÙƒÙŠÙ', 'ÙƒÙŠÙÙ…Ø§', 'ÙƒÙØ®', 'Ù„', 'Ù„Ø£Ù†', 'Ù„Ø§', 'Ù„Ø§ Ø³ÙŠÙ…Ø§', 'Ù„Ø§Øª', 'Ù„Ø§Ø²Ø§Ù„', 'Ù„Ø§Ø³ÙŠÙ…Ø§', 'Ù„Ø§Ù…', 'Ù„Ø§ÙŠØ²Ø§Ù„', 'Ù„Ø¨ÙŠÙƒ', 'Ù„Ø¯Ù†', 'Ù„Ø¯Ù‰', 'Ù„Ø¯ÙŠ', 'Ù„Ø°Ù„Ùƒ', 'Ù„Ø¹Ù„', 'Ù„Ø¹Ù„ÙÙ‘', 'Ù„Ø¹Ù…Ø±', 'Ù„Ù‚Ø§Ø¡', 'Ù„ÙƒÙ†', 'Ù„ÙƒÙ†Ù‡', 'Ù„ÙƒÙ†ÙÙ‘', 'Ù„Ù„Ø§Ù…Ù…', 'Ù„Ù…', 'Ù„Ù…Ø§', 'Ù„Ù…Ù‘Ø§', 'Ù„Ù†', 'Ù„Ù‡', 'Ù„Ù‡Ø§', 'Ù„Ù‡Ø°Ø§', 'Ù„Ù‡Ù…', 'Ù„Ùˆ', 'Ù„ÙˆÙƒØ§Ù„Ø©', 'Ù„ÙˆÙ„Ø§', 'Ù„ÙˆÙ…Ø§', 'Ù„ÙŠØª', 'Ù„ÙŠØ±Ø©', 'Ù„ÙŠØ³', 'Ù„ÙŠØ³Ø¨', 'Ù…', 'Ù…Ø¦Ø©', 'Ù…Ø¦ØªØ§Ù†', 'Ù…Ø§', 'Ù…Ø§ Ø£ÙØ¹Ù„Ù‡', 'Ù…Ø§ Ø§Ù†ÙÙƒ', 'Ù…Ø§ Ø¨Ø±Ø­', 'Ù…Ø§Ø¦Ø©', 'Ù…Ø§Ø§Ù†ÙÙƒ', 'Ù…Ø§Ø¨Ø±Ø­', 'Ù…Ø§Ø¯Ø§Ù…', 'Ù…Ø§Ø°Ø§', 'Ù…Ø§Ø±Ø³', 'Ù…Ø§Ø²Ø§Ù„', 'Ù…Ø§ÙØªØ¦', 'Ù…Ø§ÙŠ', 'Ù…Ø§ÙŠØ²Ø§Ù„', 'Ù…Ø§ÙŠÙˆ', 'Ù…ØªÙ‰', 'Ù…Ø«Ù„', 'Ù…Ø°', 'Ù…Ø±Ù‘Ø©', 'Ù…Ø³Ø§Ø¡', 'Ù…Ø¹', 'Ù…Ø¹Ø§Ø°', 'Ù…Ø¹Ù‡', 'Ù…Ù‚Ø§Ø¨Ù„', 'Ù…ÙƒØ§Ù†ÙƒÙ…', 'Ù…ÙƒØ§Ù†ÙƒÙ…Ø§', 'Ù…ÙƒØ§Ù†ÙƒÙ†Ù‘', 'Ù…ÙƒØ§Ù†ÙÙƒ', 'Ù…Ù„ÙŠØ§Ø±', 'Ù…Ù„ÙŠÙ…', 'Ù…Ù„ÙŠÙˆÙ†', 'Ù…Ù…Ø§', 'Ù…Ù†', 'Ù…Ù†Ø°', 'Ù…Ù†Ù‡', 'Ù…Ù†Ù‡Ø§', 'Ù…Ù‡', 'Ù…Ù‡Ù…Ø§', 'Ù…ÙŠÙ…', 'Ù†', 'Ù†Ø§', 'Ù†Ø¨ÙÙ‘Ø§', 'Ù†Ø­Ù†', 'Ù†Ø­Ùˆ', 'Ù†Ø¹Ù…', 'Ù†ÙØ³', 'Ù†ÙØ³Ù‡', 'Ù†Ù‡Ø§ÙŠØ©', 'Ù†ÙˆÙÙ…Ø¨Ø±', 'Ù†ÙˆÙ†', 'Ù†ÙŠØ³Ø§Ù†', 'Ù†ÙŠÙ', 'Ù†ÙØ®Ù’', 'Ù†ÙÙ‘', 'Ù‡', 'Ù‡Ø¤Ù„Ø§Ø¡', 'Ù‡Ø§', 'Ù‡Ø§Ø¡', 'Ù‡Ø§ÙƒÙ', 'Ù‡Ø¨Ù‘', 'Ù‡Ø°Ø§', 'Ù‡Ø°Ù‡', 'Ù‡Ù„', 'Ù‡Ù„Ù„Ø©', 'Ù‡Ù„Ù…', 'Ù‡Ù„Ù‘Ø§', 'Ù‡Ù…', 'Ù‡Ù…Ø§', 'Ù‡Ù…Ø²Ø©', 'Ù‡Ù†', 'Ù‡Ù†Ø§', 'Ù‡Ù†Ø§Ùƒ', 'Ù‡Ù†Ø§Ù„Ùƒ', 'Ù‡Ùˆ', 'Ù‡ÙŠ', 'Ù‡ÙŠØ§', 'Ù‡ÙŠÙ‡Ø§Øª', 'Ù‡ÙŠÙ‘Ø§', 'Ù‡ÙØ¤Ù„Ø§Ø¡', 'Ù‡ÙØ§ØªØ§Ù†Ù', 'Ù‡ÙØ§ØªÙÙŠÙ’Ù†Ù', 'Ù‡ÙØ§ØªÙÙ‡', 'Ù‡ÙØ§ØªÙÙŠ', 'Ù‡ÙØ¬Ù’', 'Ù‡ÙØ°Ø§', 'Ù‡ÙØ°Ø§Ù†Ù', 'Ù‡ÙØ°ÙÙŠÙ’Ù†Ù', 'Ù‡ÙØ°ÙÙ‡', 'Ù‡ÙØ°ÙÙŠ', 'Ù‡ÙÙŠÙ’Ù‡Ø§Øª', 'Ùˆ', 'Ùˆ6', 'ÙˆØ£Ø¨Ùˆ', 'ÙˆØ£Ù†', 'ÙˆØ§', 'ÙˆØ§Ø­Ø¯', 'ÙˆØ§Ø¶Ø§Ù', 'ÙˆØ§Ø¶Ø§ÙØª', 'ÙˆØ§ÙƒØ¯', 'ÙˆØ§Ù„ØªÙŠ', 'ÙˆØ§Ù„Ø°ÙŠ', 'ÙˆØ§Ù†', 'ÙˆØ§Ù‡Ø§Ù‹', 'ÙˆØ§Ùˆ', 'ÙˆØ§ÙˆØ¶Ø­', 'ÙˆØ¨ÙŠÙ†', 'ÙˆØ«ÙŠ', 'ÙˆØ¬Ø¯', 'ÙˆØ±Ø§Ø¡ÙÙƒ', 'ÙˆØ±Ø¯', 'ÙˆØ¹Ù„Ù‰', 'ÙˆÙÙŠ', 'ÙˆÙ‚Ø§Ù„', 'ÙˆÙ‚Ø§Ù„Øª', 'ÙˆÙ‚Ø¯', 'ÙˆÙ‚Ù', 'ÙˆÙƒØ§Ù†', 'ÙˆÙƒØ§Ù†Øª', 'ÙˆÙ„Ø§', 'ÙˆÙ„Ø§ÙŠØ²Ø§Ù„', 'ÙˆÙ„ÙƒÙ†', 'ÙˆÙ„Ù…', 'ÙˆÙ„Ù‡', 'ÙˆÙ„ÙŠØ³', 'ÙˆÙ…Ø¹', 'ÙˆÙ…Ù†', 'ÙˆÙ‡Ø¨', 'ÙˆÙ‡Ø°Ø§', 'ÙˆÙ‡Ùˆ', 'ÙˆÙ‡ÙŠ', 'ÙˆÙÙŠÙ’', 'ÙˆÙØ´Ù’ÙƒÙØ§Ù†Ù', 'Ù‰', 'ÙŠ', 'ÙŠØ§Ø¡', 'ÙŠÙØ¹Ù„Ø§Ù†', 'ÙŠÙØ¹Ù„ÙˆÙ†', 'ÙŠÙƒÙˆÙ†', 'ÙŠÙ„ÙŠ', 'ÙŠÙ…ÙƒÙ†', 'ÙŠÙ…ÙŠÙ†', 'ÙŠÙ†', 'ÙŠÙ†Ø§ÙŠØ±', 'ÙŠÙˆØ§Ù†', 'ÙŠÙˆØ±Ùˆ', 'ÙŠÙˆÙ„ÙŠÙˆ', 'ÙŠÙˆÙ…', 'ÙŠÙˆÙ†ÙŠÙˆ', 'Ù‘Ø£ÙŠÙ‘Ø§Ù†']\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import glob\n",
    "import codecs\n",
    "from keras.preprocessing.text import Tokenizer ,text_to_word_sequence\n",
    "def get_stop_words():\n",
    "    path='list.txt'\n",
    "    stop_words = []\n",
    "    with codecs.open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as myfile:\n",
    "        stop_words = myfile.readlines()\n",
    "    stop_words = [word.strip() for word in stop_words]\n",
    "    return stop_words\n",
    "stop_words=get_stop_words()\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## remove stop words from text\n",
    "shuffled_data['text']=shuffled_data['text'].apply(lambda x : [item for item in x.split() if item not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8305                                        [Ù…Ø¹Ø¬Ø¨, Ø³Ø±ÙŠ, ğŸ¤”]\n",
       "22198    [Ø§Ø¹Ù„Ù‚, Ø§Ø­Ù„Ø§Ù…ÙŠ, Ø­Ø§ÙØ©, #Ø§Ù„ØºÙŠÙ…, Ø·Ø­Ù†Ø§, #ØºÙŠØ«, Ø¨Ù‚ÙŠÙ†Ø§...\n",
       "6516                                        [Ø®Ø±Ø¨Øª, ğŸ˜œ, ğŸ‘‡ğŸ˜‚ğŸ˜‚]\n",
       "10638                                    [ÙŠØ³Ø¹Ø¯, ØµØ¨Ø§Ø§Ø­Ùƒ, ğŸŒ¹]\n",
       "6470     [ÙƒØ§ØªØ¨Ùˆ, Ø±Ø¨, Ø§Ù„Ø¹Ø¨Ø§Ø¯, ØªØ´ÙˆÙÙˆ, Ø§Ù„Ø¹ÙŠÙ†, ÙˆØ§Ù„Ø£Ø¬Ø¯Ø±, ÙŠÙÙˆ...\n",
       "                               ...                        \n",
       "12487                  [Ø´ÙØªÙ‡, Ø¨Ø¹Ù‚Ù„ÙŠ, ÙˆØ¹ÙŠÙ†ÙŠ, Ø¥Ù„Ø§, ØªØ¯Ù…Ø¹Ù‡, ğŸ’™]\n",
       "21794       [Ø­Ø³Ù†, Ø¹ÙŠÙˆØ¨Ùƒ, ÙŠØµÙØ¹Ùƒ, Ø§Ø­Ø¯Ø§Ù‡Ù…, Ù…Ø¯Ø¹ÙŠØ§, Ø§Ù„Ù…Ø¹Ø±ÙØ©, ğŸ˜¶]\n",
       "2684     [Ù„ÙŠ, ØµØ§Ø­Ø¨, Ø§ØºÙ„Ø§, Ø§Ù„Ù†ÙØ³, Ø¨Ø´ÙˆÙŠ, ÙˆÙŠØ²ÙŠØ¯, Ø¨Ø§Ù‚ÙŠ, Ø§Ù„Ù…...\n",
       "763                         [Ù‡Ø°Ø§Ùƒ, Ø§Ù„Ø­ÙŠÙ†, Ø§Ù„ÙˆØ¶Ø¹, Ø­ÙØ§Ù„ÙŠ, ğŸ’”]\n",
       "16772    [ÙŠÙ‚Ù„Ùƒ, Ù‚ØµÙŠØ±Ù‡, Ù„Ø¨Ø³Øª, ÙƒØ¹Ø¨, Ø²ÙƒÙ…Øª, Ù„ÙŠÙŠÙ‡ØŸØŸ, ØªØºÙŠØ±, Ø§...\n",
       "Name: text, Length: 45273, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_data.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8305                                        [Ù…Ø¹Ø¬Ø¨, Ø³Ø±ÙŠ, ğŸ¤”]\n",
       "22198    [Ø§Ø¹Ù„Ù‚, Ø§Ø­Ù„Ø§Ù…ÙŠ, Ø­Ø§ÙØ©, #Ø§Ù„ØºÙŠÙ…, Ø·Ø­Ù†Ø§, #ØºÙŠØ«, Ø¨Ù‚ÙŠÙ†Ø§...\n",
       "6516                                        [Ø®Ø±Ø¨Øª, ğŸ˜œ, ğŸ‘‡ğŸ˜‚ğŸ˜‚]\n",
       "10638                                    [ÙŠØ³Ø¹Ø¯, ØµØ¨Ø§Ø§Ø­Ùƒ, ğŸŒ¹]\n",
       "6470     [ÙƒØ§ØªØ¨Ùˆ, Ø±Ø¨, Ø§Ù„Ø¹Ø¨Ø§Ø¯, ØªØ´ÙˆÙÙˆ, Ø§Ù„Ø¹ÙŠÙ†, ÙˆØ§Ù„Ø£Ø¬Ø¯Ø±, ÙŠÙÙˆ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_data['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_sequence_length=85\n",
    "max_nm_words=len(w2v.vocab)\n",
    "embeding_dim=300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  fit_on_texts\n",
    "Updates internal vocabulary based on a list of texts. This method creates the vocabulary index based on word frequency.\n",
    "#### texts_to_sequences\n",
    "Transforms each text in texts to a sequence of integers. So it basically takes each word in the text and replaces it with its corresponding integer value from the word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83181\n"
     ]
    }
   ],
   "source": [
    "## tokenize data\n",
    "tokenizer= Tokenizer()\n",
    "tokenizer.fit_on_texts(shuffled_data['text'])\n",
    "word_index=tokenizer.word_index\n",
    "vocab_size=len(word_index)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_sequences=tokenizer.texts_to_sequences(shuffled_data['text'])\n",
    "train_paded_sequences=pad_sequences(train_sequences,maxlen=max_sequence_length,padding='post',truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45273"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_paded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_paded_sequences,valid_paded_sequences,y_train,y_valid=train_test_split(train_paded_sequences,shuffled_data['sentiment'].values,test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\abdullah\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\users\\abdullah\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "### build model\n",
    "sentence_indices = Input(shape=(max_sequence_length,),dtype='int32')\n",
    "embedding_layer = Embedding(vocab_size+1 , embeding_dim,  input_length=max_sequence_length)\n",
    "embeddings = embedding_layer(sentence_indices)   \n",
    "X = LSTM(60, return_sequences=True, dropout=0.1, recurrent_dropout=0.1)(embeddings)\n",
    "X = GlobalMaxPool1D()(X)\n",
    "X = Dropout(0.2)(X)\n",
    "X = Dense(128)(X)\n",
    "X = Activation(\"relu\")(X)\n",
    "X = Dropout(0.2)(X)\n",
    "X = Dense(512)(X)\n",
    "X = Activation(\"relu\")(X)\n",
    "X = Dropout(0.2)(X)\n",
    "X = Dense(1)(X)\n",
    "X = Activation('softmax')(X)\n",
    "model = Model(inputs=sentence_indices,outputs=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\abdullah\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From c:\\users\\abdullah\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 36218 samples, validate on 9055 samples\n",
      "Epoch 1/2\n",
      "36218/36218 [==============================] - 750s 21ms/step - loss: 7.9175 - acc: 0.5034 - val_loss: 7.9686 - val_acc: 0.5002\n",
      "Epoch 2/2\n",
      "36218/36218 [==============================] - 826s 23ms/step - loss: 7.9175 - acc: 0.5034 - val_loss: 7.9686 - val_acc: 0.5002\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_paded_sequences, y_train, batch_size=32, epochs=2, validation_data=(valid_paded_sequences, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load The model and predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
